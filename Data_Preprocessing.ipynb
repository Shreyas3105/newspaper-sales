{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68d1ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b15f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236ddcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries for 'unsold' and 'supply' DataFrames\n",
    "unsold_dataframes = {}\n",
    "supply_dataframes = {}\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Extract month and year from the filename\n",
    "        month_year = filename.split(' ')[-1].split('.')[0]  # Extracting the month'year from the filename\n",
    "\n",
    "        # Read the Excel file into a dictionary of DataFrames (one DataFrame per sheet)\n",
    "        excel_data = pd.read_excel(file_path, sheet_name=None, header=1)\n",
    "\n",
    "        # Iterate through sheets and store each DataFrame in the respective dictionaries\n",
    "        for sheet_name, df in excel_data.items():\n",
    "            df_name = f\"{sheet_name}_{month_year}\"\n",
    "            \n",
    "            if sheet_name.lower() == 'unsold':\n",
    "                unsold_dataframes[df_name] = df\n",
    "            elif sheet_name.lower() == 'supply':\n",
    "                supply_dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33005eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_supply_dataframe(dataframe, month_year_str, column_name):\n",
    "    df_new = dataframe.drop(['Avg. PO', 'Total', 'Week', 'Sun', 'Avg. Wk Supply', 'Avg. Sun Supply'], axis=1)\n",
    "    df_new = pd.melt(df_new, id_vars = ['CODE', 'AGENT NAME', 'STATION'], var_name='Date', value_name=column_name)\n",
    "    df_new[['Day', 'Day_of_week']] = df_new['Date'].str.split(' ', 1, expand=True)\n",
    "    df_new['Day'] = pd.to_numeric(df_new['Day'], errors='coerce')\n",
    "    # Extract month and year from the input string\n",
    "    month_year = month_year_str.strip().replace(\"'\", \" \").split(\" \")\n",
    "    month, year = month_year[0], month_year[1]\n",
    "    # Create a new 'Date' column with the format 'YYYY-MM-DD'\n",
    "    month_str = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'June': '06',\n",
    "                 'July': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}[month]\n",
    "    # Create the datetime col\n",
    "    df_new['Date'] = pd.to_datetime(f'20{year}-{month_str}-' + df_new['Day'].astype(str), errors='coerce')\n",
    "    df_new = df_new.dropna(subset=['CODE'])\n",
    "    df_new.loc[:,'AGENT NAME'] = df_new['AGENT NAME'].fillna(method='ffill').copy()\n",
    "    df_new = df_new.drop(['Day', 'Day_of_week'], axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8457ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unsold_dataframe(dataframe, column_name):\n",
    "    df_new = dataframe.drop(['Total', 'Wkday', 'Sunday'], axis=1)\n",
    "    df_new = pd.melt(df_new, id_vars = ['CODE', 'AGENT NAME', 'STATION'], var_name='Date', value_name=column_name)\n",
    "    df_new['Date'] = pd.to_datetime(df_new['Date'], format='%d.%m.%y', errors='coerce')\n",
    "    df_new = df_new.dropna(subset=['CODE'])\n",
    "    df_new.loc[:,'AGENT NAME'] = df_new['AGENT NAME'].fillna(method='ffill').copy()\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70c5445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_supply_dataframes = []  # List to store the converted DataFrames\n",
    "\n",
    "# Example: Applying the function to a DataFrame in supply_dataframes\n",
    "for key, dataframe in supply_dataframes.items():\n",
    "    sheet_name, month_year_str = key.split('_')\n",
    "    converted_df_name = f\"{sheet_name}_converted_{month_year_str}\"\n",
    "    # Applying the conversion function\n",
    "    converted_df = convert_supply_dataframe(dataframe, month_year_str, 'Supply')\n",
    "    \n",
    "    # Store the converted DataFrame in the list\n",
    "    converted_supply_dataframes.append(converted_df)\n",
    "\n",
    "# Concatenate all the converted DataFrames into one DataFrame\n",
    "final_supply_dataframe = pd.concat(converted_supply_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bfd0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_unsold_dataframes = []  # List to store the converted DataFrames\n",
    "\n",
    "# Example: Applying the function to a DataFrame in supply_dataframes\n",
    "for key, dataframe in unsold_dataframes.items():\n",
    "    sheet_name, month_year_str = key.split('_')\n",
    "    converted_df_name = f\"{sheet_name}_converted_{month_year_str}\"\n",
    "    # Applying the conversion function\n",
    "    converted_df = convert_unsold_dataframe(dataframe, 'Unsold')\n",
    "    \n",
    "    # Store the converted DataFrame in the list\n",
    "    converted_unsold_dataframes.append(converted_df)\n",
    "\n",
    "# Concatenate all the converted DataFrames into one DataFrame\n",
    "final_unsold_dataframe = pd.concat(converted_unsold_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25bb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_supply_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_supply_dataframe, final_unsold_dataframe[['CODE', 'Date', 'Unsold']], on=['CODE', 'Date'], how='left')\n",
    "final_df['Net_Sales'] = (final_df['Supply'] - final_df['Unsold'].fillna(0))\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.sort_values(by='Date')\n",
    "final_df['Day_of_the_Week'] = final_df['Date'].dt.day_name()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b769481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Results/2023_sales_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datewise_sales = final_df.groupby('Date').agg({\n",
    "    'Supply': 'sum',\n",
    "    'Unsold': 'sum',  # Assuming 'Unsold' is a numerical column, otherwise, modify the aggregation accordingly\n",
    "    'Net_Sales': 'sum'\n",
    "}).reset_index()\n",
    "datewise_sales['Day_of_the_Week'] = datewise_sales['Date'].dt.day_name()\n",
    "\n",
    "datewise_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb7d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datewise_sales.to_csv(\"Results/2023_Datewise_sales.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
